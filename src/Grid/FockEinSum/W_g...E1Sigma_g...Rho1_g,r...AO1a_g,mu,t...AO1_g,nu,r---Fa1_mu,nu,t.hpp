/*
Generated by EigenEinSum

Recommended filename:
W_g...E1Sigma_g...Rho1_g,r...AO1a_g,mu,t...AO1_g,nu,r---Fa1_mu,nu,t.hpp

Einsum expression:
W(g), E1Sigma(g), Rho1(g, r), AO1a(g, mu, t), AO1(g, nu, r) -> Fa1(mu, nu, t)

The einsum expression is decomposed into:
W(g), E1Sigma(g) -> WE1Sigma(g)
WE1Sigma(g), Rho1(g, r) -> WE1SigmaRho1(g, r)
WE1SigmaRho1(g, r), AO1a(g, mu, t) -> WE1SigmaRho1AO1a(g, mu, r, t)
WE1SigmaRho1AO1a(g, mu, r, t), AO1(g, nu, r) -> Fa1(mu, nu, t)

The index paths are derived to be:
TOP
├── g
├── r
│   └── g
└── t
    └── r
        ├── mu
        │   └── g
        └── nu
            └── mu
                └── g
*/
{
	[[maybe_unused]] const int mu_len = AO1a.dimension(1);
	assert( mu_len == Fa1.dimension(0) );
	[[maybe_unused]] const int nu_len = AO1.dimension(1);
	assert( nu_len == Fa1.dimension(1) );
	[[maybe_unused]] const int t_len = AO1a.dimension(2);
	assert( t_len == Fa1.dimension(2) );
	[[maybe_unused]] const int g_len = W.dimension(0);
	assert( g_len == E1Sigma.dimension(0) );
	assert( g_len == Rho1.dimension(0) );
	assert( g_len == AO1a.dimension(0) );
	assert( g_len == AO1.dimension(0) );
	[[maybe_unused]] const int r_len = Rho1.dimension(1);
	assert( r_len == AO1.dimension(2) );
	EigenTensor<1> WE1Sigma(g_len);
	EigenTensor<2> WE1SigmaRho1(g_len, r_len);
	EigenTensor<2> WE1SigmaRho1AO1atr(g_len, mu_len);
	WE1Sigma.setZero();
	WE1SigmaRho1.setZero();
	double* WE1Sigma_ = &WE1Sigma(0);
	const double* W_ = &W(0);
	const double* E1Sigma_ = &E1Sigma(0);
	#pragma omp simd simdlen(8) aligned(WE1Sigma_, W_, E1Sigma_: 64)
	for ( int g = 0; g < g_len; g++ ){
		WE1Sigma_[g] += W_[g] * E1Sigma_[g];
	}
	for ( int r = 0; r < r_len; r++ ){
		double* WE1SigmaRho1_r = &WE1SigmaRho1(0, r);
		const double* WE1Sigma_ = &WE1Sigma(0);
		const double* Rho1_r = &Rho1(0, r);
		#pragma omp simd simdlen(8) aligned(WE1SigmaRho1_r, WE1Sigma_, Rho1_r: 64)
		for ( int g = 0; g < g_len; g++ ){
			WE1SigmaRho1_r[g] += WE1Sigma_[g] * Rho1_r[g];
		}
	}
	for ( int t = 0; t < t_len; t++ ){
		for ( int r = 0; r < r_len; r++ ){
			WE1SigmaRho1AO1atr.setZero();
			for ( int mu = 0; mu < mu_len; mu++ ){
				double* WE1SigmaRho1AO1atr_mu = &WE1SigmaRho1AO1atr(0, mu);
				const double* WE1SigmaRho1_r = &WE1SigmaRho1(0, r);
				const double* AO1a_mut = &AO1a(0, mu, t);
				#pragma omp simd simdlen(8) aligned(WE1SigmaRho1AO1atr_mu, WE1SigmaRho1_r, AO1a_mut: 64)
				for ( int g = 0; g < g_len; g++ ){
					WE1SigmaRho1AO1atr_mu[g] += WE1SigmaRho1_r[g] * AO1a_mut[g];
				}
			}
			for ( int nu = 0; nu < nu_len; nu++ ){
				for ( int mu = 0; mu < mu_len; mu++ ){
					double Fa1munut = 0;
					const double* WE1SigmaRho1AO1atr_mu = &WE1SigmaRho1AO1atr(0, mu);
					const double* AO1_nur = &AO1(0, nu, r);
					#pragma omp simd simdlen(8) reduction(+: Fa1munut) aligned(WE1SigmaRho1AO1atr_mu, AO1_nur: 64)
					for ( int g = 0; g < g_len; g++ ){
						Fa1munut += WE1SigmaRho1AO1atr_mu[g] * AO1_nur[g];
					}
					Fa1(mu, nu, t) += Fa1munut;
				}
			}
		}
	}
}
