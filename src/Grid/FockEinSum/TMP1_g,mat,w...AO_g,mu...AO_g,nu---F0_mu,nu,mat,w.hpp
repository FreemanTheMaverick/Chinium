/*
Generated by EigenEinSum

Recommended filename:
TMP1_g,mat,w...AO_g,mu...AO_g,nu---F0_mu,nu,mat,w.hpp

Einsum expression:
TMP1(g, mat, w), AO(g, mu), AO(g, nu) -> F0(mu, nu, mat, w)

The einsum expression is decomposed into:
TMP1(g, mat, w), AO(g, mu) -> TMP1AO(g, mu, mat, w)
TMP1AO(g, mu, mat, w), AO(g, nu) -> F0(mu, nu, mat, w)

The index paths are derived to be:
TOP
└── w
    └── mat
        └── mu
            ├── g
            └── nu
                └── g
*/
{
	[[maybe_unused]] const int mu_len = AO.dimension(1);
	assert( mu_len == F0.dimension(0) );
	[[maybe_unused]] const int nu_len = AO.dimension(1);
	assert( nu_len == F0.dimension(1) );
	[[maybe_unused]] const int mat_len = TMP1.dimension(1);
	assert( mat_len == F0.dimension(2) );
	[[maybe_unused]] const int w_len = TMP1.dimension(2);
	assert( w_len == F0.dimension(3) );
	[[maybe_unused]] const int g_len = TMP1.dimension(0);
	assert( g_len == AO.dimension(0) );
	Eigen::Tensor<double, 1> TMP1AOwmatmu(g_len);
	for ( int w = 0; w < w_len; w++ ){
		for ( int mat = 0; mat < mat_len; mat++ ){
			for ( int mu = 0; mu < mu_len; mu++ ){
				TMP1AOwmatmu.setZero();
				double* TMP1AOwmatmu_ = &TMP1AOwmatmu(0);
				const double* TMP1_matw = &TMP1(0, mat, w);
				const double* AO_mu = &AO(0, mu);
				#pragma omp simd simdlen(8) aligned(TMP1AOwmatmu_, TMP1_matw, AO_mu: 64)
				for ( int g = 0; g < g_len; g++ ){
					TMP1AOwmatmu_[g] += TMP1_matw[g] * AO_mu[g];
				}
				for ( int nu = 0; nu < nu_len; nu++ ){
					double _F0munumatw = 0;
					const double* TMP1AOwmatmu_ = &TMP1AOwmatmu(0);
					const double* AO_nu = &AO(0, nu);
					#pragma omp simd simdlen(8) reduction(+: _F0munumatw) aligned(TMP1AOwmatmu_, AO_nu: 64)
					for ( int g = 0; g < g_len; g++ ){
						_F0munumatw += TMP1AOwmatmu_[g] * AO_nu[g];
					}
					F0(mu, nu, mat, w) += _F0munumatw;
				}
			}
		}
	}
}
