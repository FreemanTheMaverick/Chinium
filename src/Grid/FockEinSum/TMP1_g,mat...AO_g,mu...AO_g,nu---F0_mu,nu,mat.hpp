/*
Generated by EigenEinSum

Recommended filename:
TMP1_g,mat...AO_g,mu...AO_g,nu---F0_mu,nu,mat.hpp

Einsum expression:
TMP1(g, mat), AO(g, mu), AO(g, nu) -> F0(mu, nu, mat)

The einsum expression is decomposed into:
TMP1(g, mat), AO(g, mu) -> TMP1AO(g, mu, mat)
TMP1AO(g, mu, mat), AO(g, nu) -> F0(mu, nu, mat)

The index paths are derived to be:
TOP
└── mat
    ├── mu
    │   └── g
    └── nu
        └── mu
            └── g
*/
{
	[[maybe_unused]] const int mu_len = AO.dimension(1);
	assert( mu_len == F0.dimension(0) );
	[[maybe_unused]] const int nu_len = AO.dimension(1);
	assert( nu_len == F0.dimension(1) );
	[[maybe_unused]] const int mat_len = TMP1.dimension(1);
	assert( mat_len == F0.dimension(2) );
	[[maybe_unused]] const int g_len = TMP1.dimension(0);
	assert( g_len == AO.dimension(0) );
	EigenTensor<2> TMP1AOmat(g_len, mu_len);
	for ( int mat = 0; mat < mat_len; mat++ ){
		TMP1AOmat.setZero();
		for ( int mu = 0; mu < mu_len; mu++ ){
			double* TMP1AOmat_mu = &TMP1AOmat(0, mu);
			const double* TMP1_mat = &TMP1(0, mat);
			const double* AO_mu = &AO(0, mu);
			#pragma omp simd simdlen(8) aligned(TMP1AOmat_mu, TMP1_mat, AO_mu: 64)
			for ( int g = 0; g < g_len; g++ ){
				TMP1AOmat_mu[g] += TMP1_mat[g] * AO_mu[g];
			}
		}
		for ( int nu = 0; nu < nu_len; nu++ ){
			for ( int mu = 0; mu < mu_len; mu++ ){
				double F0munumat = 0;
				const double* TMP1AOmat_mu = &TMP1AOmat(0, mu);
				const double* AO_nu = &AO(0, nu);
				#pragma omp simd simdlen(8) reduction(+: F0munumat) aligned(TMP1AOmat_mu, AO_nu: 64)
				for ( int g = 0; g < g_len; g++ ){
					F0munumat += TMP1AOmat_mu[g] * AO_nu[g];
				}
				F0(mu, nu, mat) += F0munumat;
			}
		}
	}
}
