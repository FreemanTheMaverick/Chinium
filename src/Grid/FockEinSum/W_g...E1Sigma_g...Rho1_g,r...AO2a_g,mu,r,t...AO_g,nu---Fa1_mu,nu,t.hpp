/*
Generated by EigenEinSum

Recommended filename:
W_g...E1Sigma_g...Rho1_g,r...AO2a_g,mu,r,t...AO_g,nu---Fa1_mu,nu,t.hpp

Einsum expression:
W(g), E1Sigma(g), Rho1(g, r), AO2a(g, mu, r|t), AO(g, nu) -> Fa1(mu, nu, t)

The einsum expression is decomposed into:
W(g), E1Sigma(g) -> WE1Sigma(g)
WE1Sigma(g), Rho1(g, r) -> WE1SigmaRho1(g, r)
WE1SigmaRho1(g, r), AO2a(g, mu, r|t) -> WE1SigmaRho1AO2a(g, mu, t)
WE1SigmaRho1AO2a(g, mu, t), AO(g, nu) -> Fa1(mu, nu, t)

The index paths are derived to be:
TOP
├── g
├── r
│   └── g
└── t
    ├── r
    │   └── mu
    │       └── g
    └── nu
        └── mu
            └── g
*/
{
	[[maybe_unused]] const int mu_len = AO2a.dimension(1);
	assert( mu_len == Fa1.dimension(0) );
	[[maybe_unused]] const int nu_len = AO.dimension(1);
	assert( nu_len == Fa1.dimension(1) );
	[[maybe_unused]] const int t_len = Fa1.dimension(2);
	[[maybe_unused]] const int g_len = W.dimension(0);
	assert( g_len == E1Sigma.dimension(0) );
	assert( g_len == Rho1.dimension(0) );
	assert( g_len == AO2a.dimension(0) );
	assert( g_len == AO.dimension(0) );
	[[maybe_unused]] const int r_len = Rho1.dimension(1);
	[[maybe_unused]] const int r_t_len = AO2a.dimension(2);
	EigenTensor<1> WE1Sigma(g_len);
	EigenTensor<2> WE1SigmaRho1(g_len, r_len);
	EigenTensor<2> WE1SigmaRho1AO2at(g_len, mu_len);
	WE1Sigma.setZero();
	WE1SigmaRho1.setZero();
	double* WE1Sigma_ = &WE1Sigma(0);
	const double* W_ = &W(0);
	const double* E1Sigma_ = &E1Sigma(0);
	#pragma omp simd simdlen(8) aligned(WE1Sigma_, W_, E1Sigma_: 64)
	for ( int g = 0; g < g_len; g++ ){
		WE1Sigma_[g] += W_[g] * E1Sigma_[g];
	}
	for ( int r = 0; r < r_len; r++ ){
		double* WE1SigmaRho1_r = &WE1SigmaRho1(0, r);
		const double* WE1Sigma_ = &WE1Sigma(0);
		const double* Rho1_r = &Rho1(0, r);
		#pragma omp simd simdlen(8) aligned(WE1SigmaRho1_r, WE1Sigma_, Rho1_r: 64)
		for ( int g = 0; g < g_len; g++ ){
			WE1SigmaRho1_r[g] += WE1Sigma_[g] * Rho1_r[g];
		}
	}
	for ( int t = 0; t < t_len; t++ ){
		WE1SigmaRho1AO2at.setZero();
		for ( int r = 0; r < r_len; r++ ){
			int index_array_r_t[] = {r, t}; std::sort(index_array_r_t, index_array_r_t + 2); const int r_t = ( index_array_r_t[0] + 0 ) / 1 + ( index_array_r_t[1] + 0 ) * ( index_array_r_t[1] + 1 ) / 2;
			for ( int mu = 0; mu < mu_len; mu++ ){
				double* WE1SigmaRho1AO2at_mu = &WE1SigmaRho1AO2at(0, mu);
				const double* WE1SigmaRho1_r = &WE1SigmaRho1(0, r);
				const double* AO2a_mur_t = &AO2a(0, mu, r_t);
				#pragma omp simd simdlen(8) aligned(WE1SigmaRho1AO2at_mu, WE1SigmaRho1_r, AO2a_mur_t: 64)
				for ( int g = 0; g < g_len; g++ ){
					WE1SigmaRho1AO2at_mu[g] += WE1SigmaRho1_r[g] * AO2a_mur_t[g];
				}
			}
		}
		for ( int nu = 0; nu < nu_len; nu++ ){
			for ( int mu = 0; mu < mu_len; mu++ ){
				double Fa1munut = 0;
				const double* WE1SigmaRho1AO2at_mu = &WE1SigmaRho1AO2at(0, mu);
				const double* AO_nu = &AO(0, nu);
				#pragma omp simd simdlen(8) reduction(+: Fa1munut) aligned(WE1SigmaRho1AO2at_mu, AO_nu: 64)
				for ( int g = 0; g < g_len; g++ ){
					Fa1munut += WE1SigmaRho1AO2at_mu[g] * AO_nu[g];
				}
				Fa1(mu, nu, t) += Fa1munut;
			}
		}
	}
}
