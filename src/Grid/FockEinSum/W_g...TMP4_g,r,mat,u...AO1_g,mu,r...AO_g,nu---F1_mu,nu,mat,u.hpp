/*
Generated by EigenEinSum

Recommended filename:
W_g...TMP4_g,r,mat,u...AO1_g,mu,r...AO_g,nu---F1_mu,nu,mat,u.hpp

Einsum expression:
W(g), TMP4(g, r, mat, u), AO1(g, mu, r), AO(g, nu) -> F1(mu, nu, mat, u)

The einsum expression is decomposed into:
W(g), TMP4(g, r, mat, u) -> WTMP4(g, r, mat, u)
WTMP4(g, r, mat, u), AO1(g, mu, r) -> WTMP4AO1(g, mu, mat, u)
WTMP4AO1(g, mu, mat, u), AO(g, nu) -> F1(mu, nu, mat, u)

The index paths are derived to be:
TOP
└── u
    └── mat
        ├── r
        │   ├── g
        │   └── mu
        │       └── g
        └── mu
            └── nu
                └── g
*/
{
	[[maybe_unused]] const int mu_len = AO1.dimension(1);
	assert( mu_len == F1.dimension(0) );
	[[maybe_unused]] const int nu_len = AO.dimension(1);
	assert( nu_len == F1.dimension(1) );
	[[maybe_unused]] const int mat_len = TMP4.dimension(2);
	assert( mat_len == F1.dimension(2) );
	[[maybe_unused]] const int u_len = TMP4.dimension(3);
	assert( u_len == F1.dimension(3) );
	[[maybe_unused]] const int g_len = W.dimension(0);
	assert( g_len == TMP4.dimension(0) );
	assert( g_len == AO1.dimension(0) );
	assert( g_len == AO.dimension(0) );
	[[maybe_unused]] const int r_len = TMP4.dimension(1);
	assert( r_len == AO1.dimension(2) );
	Eigen::Tensor<double, 2> WTMP4AO1umat(g_len, mu_len);
	Eigen::Tensor<double, 1> WTMP4umatr(g_len);
	for ( int u = 0; u < u_len; u++ ){
		for ( int mat = 0; mat < mat_len; mat++ ){
			WTMP4AO1umat.setZero();
			for ( int r = 0; r < r_len; r++ ){
				WTMP4umatr.setZero();
				double* WTMP4umatr_ = &WTMP4umatr(0);
				const double* W_ = &W(0);
				const double* TMP4_rmatu = &TMP4(0, r, mat, u);
				#pragma omp simd simdlen(8) aligned(WTMP4umatr_, W_, TMP4_rmatu: 64)
				for ( int g = 0; g < g_len; g++ ){
					WTMP4umatr_[g] += W_[g] * TMP4_rmatu[g];
				}
				for ( int mu = 0; mu < mu_len; mu++ ){
					double* WTMP4AO1umat_mu = &WTMP4AO1umat(0, mu);
					const double* WTMP4umatr_ = &WTMP4umatr(0);
					const double* AO1_mur = &AO1(0, mu, r);
					#pragma omp simd simdlen(8) aligned(WTMP4AO1umat_mu, WTMP4umatr_, AO1_mur: 64)
					for ( int g = 0; g < g_len; g++ ){
						WTMP4AO1umat_mu[g] += WTMP4umatr_[g] * AO1_mur[g];
					}
				}
			}
			for ( int mu = 0; mu < mu_len; mu++ ){
				for ( int nu = 0; nu < nu_len; nu++ ){
					double _F1munumatu = 0;
					const double* WTMP4AO1umat_mu = &WTMP4AO1umat(0, mu);
					const double* AO_nu = &AO(0, nu);
					#pragma omp simd simdlen(8) reduction(+: _F1munumatu) aligned(WTMP4AO1umat_mu, AO_nu: 64)
					for ( int g = 0; g < g_len; g++ ){
						_F1munumatu += WTMP4AO1umat_mu[g] * AO_nu[g];
					}
					F1(mu, nu, mat, u) += _F1munumatu;
				}
			}
		}
	}
}
